### Problem Statement

The **Least Recently Used (LRU) Cache** is a data structure that efficiently handles data retrieval and insertion while maintaining a fixed capacity. The problem asks to implement an LRU cache where:
- The cache stores key-value pairs.
- It can retrieve a value based on the key.
- It can insert a new key-value pair.
- When the cache exceeds its capacity, the least recently used key-value pair should be evicted to make room for the new data.

The operations supported are:
- **get(key)**: Retrieves the value associated with `key` if it exists in the cache; otherwise, returns `-1`.
- **put(key, value)**: Inserts a key-value pair into the cache. If the key already exists, it updates the value and makes the key the most recently used. If the cache exceeds its capacity, it removes the least recently used key.

For example:
- **Input**: `LRUCache(2)`, `put(1, 1)`, `put(2, 2)`, `get(1)`, `put(3, 3)`, `get(2)`, `put(4, 4)`, `get(1)`, `get(3)`, `get(4)`
- **Output**: `1, -1, 3, 4`

### Approach

The key challenge in implementing the LRU cache is to efficiently manage the insertion, retrieval, and eviction of elements. For an optimal solution, we need to:
1. **Quickly access values** using keys.
2. **Track the usage order** of keys, ensuring that the most recently used elements are easy to identify and remove the least recently used element when the capacity is exceeded.

To achieve this efficiently, we can use a combination of two data structures:
- **Doubly Linked List**: This allows us to reorder the elements and efficiently remove the least recently used item from the list.
- **Hash Map (or unordered_map)**: This provides **O(1)** access time for retrieving values based on the key.

Here’s how the LRU Cache works:
- **Doubly Linked List**: The most recently used elements are stored at the front of the list, and the least recently used elements are stored at the back. When a key is accessed or inserted, it is moved to the front of the list.
- **Hash Map**: This stores key-value pairs and maps each key to its corresponding node in the doubly linked list. This provides efficient lookups for retrieving and modifying values.

### Code Breakdown (Step by Step)

#### Step 1: Data Structures

```cpp
map<int, list<pair<int, int>>::iterator> mp;
list<pair<int, int>> q;
```

- `mp`: A **map** is used to associate each key with its corresponding node in the doubly linked list `q`. This allows **O(1)** access to the node where the key-value pair is stored.
- `q`: A **doubly linked list** stores the key-value pairs as `pair<int, int>` elements. The most recently used items are moved to the front, while the least recently used ones are at the back.

#### Step 2: Constructor

```cpp
LRUCache(int capacity) {
    cap = capacity;
}
```

- The constructor initializes the cache with a specified `capacity` and prepares the `map` and `list`.

#### Step 3: `get` Method

```cpp
int get(int key) {
    if(!mp.count(key)) return -1;
    auto it = *mp[key];
    q.erase(mp[key]);
    q.push_front(make_pair(key, it.second));
    mp[key] = q.begin();
    return it.second;
}
```

- **Check if the key exists**: First, we check if the key exists in the cache using `mp.count(key)`. If not, we return `-1`.
- **Move to the front**: If the key exists, we retrieve the corresponding node (`it = *mp[key]`), then erase it from its current position in the list and move it to the front of the list to mark it as the most recently used.
- **Update the map**: We update the map to point to the new location of the key in the list (the front).
- **Return value**: Finally, we return the value associated with the key.

#### Step 4: `put` Method

```cpp
void put(int key, int value) {
    if(mp.count(key)) {
        q.erase(mp[key]);
        q.push_front(make_pair(key, value));
        mp[key] = q.begin();
    } else {
        q.push_front(make_pair(key, value));
        mp[key] = q.begin();
        if(q.size() > cap) {
            mp.erase(q.back().first);
            q.pop_back();
        }
    }
}
```

- **Update existing key**: If the key already exists in the cache, we remove its current position from the list, update its value, and move it to the front.
- **Insert new key**: If the key does not exist, we simply add the key-value pair to the front of the list.
- **Evict least recently used element**: If the cache exceeds its capacity, we remove the least recently used item (the item at the back of the list). This is done by erasing the entry from the map and popping the last node from the list.

#### Step 5: Eviction Logic

```cpp
if(q.size() > cap) {
    mp.erase(q.back().first);
    q.pop_back();
}
```

- When the cache exceeds the `capacity`, we remove the least recently used element from both the `map` and the `list`. The last element in the list is the least recently used, so we erase it from the map and remove it from the list.

### Complexity

#### Time Complexity:
- **get(key)**: **O(1)** – Accessing an element in the map and moving it to the front of the list both take constant time.
- **put(key, value)**: **O(1)** – Insertion and removal operations in the map and the list both take constant time. Eviction also takes constant time, as we only remove one element from the list and the map.

#### Space Complexity:
- **O(capacity)** – The space complexity is proportional to the cache’s capacity. The map stores the keys and their corresponding list iterators, while the list stores the key-value pairs.

### Conclusion

This **LRU Cache** implementation is highly efficient, providing **O(1)** time complexity for both `get` and `put` operations. By using a combination of a **doubly linked list** and a **hash map**, the solution efficiently manages cache access and eviction, ensuring that the most recently used items are kept in the cache while the least recently used items are evicted when the cache exceeds its capacity. This solution is both time and space-efficient, making it well-suited for handling real-time caching scenarios where fast access and limited storage are critical.