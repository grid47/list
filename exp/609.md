### Problem Statement
Given a list of paths, each containing a directory and files with their content, identify and group files that have the same content. Each file is represented as "filename(content)", where `filename` is the name of the file and `content` is the content within parentheses.

### Approach
1. **Parsing the Input**:
   - For each string in the `paths` list, split it into the directory and the files.
   - The first element of the string represents the root directory.
   - The remaining elements represent files and their content.

2. **Storing Content**:
   - Use a hash map (`unordered_map`) to store file contents as keys and the corresponding full file paths as values.
   - The key will be the content of the file (the part inside parentheses), and the value will be a list of file paths that share that content.

3. **Building the Result**:
   - After processing all paths, iterate through the hash map and collect all file paths where the content appears more than once.

4. **Output**:
   - Return a list of lists, where each inner list contains paths of files with identical content.

### Code Walk-through
- The `findDuplicate` function takes a vector of strings (`paths`).
- It initializes an unordered map (`mp`) to map file contents to their corresponding file paths.
- For each path:
  - Split the path using a string stream.
  - Read the root directory and each subsequent file.
  - Construct the full path and extract the content.
  - Store the full path in the map using content as the key.
- Finally, check the map for entries with more than one path and add those to the result.

### Complexity
- **Time Complexity**: O(N), where N is the total number of characters in all strings, as each character is processed once.
- **Space Complexity**: O(M), where M is the number of unique file contents, as each unique content can potentially store multiple paths.
